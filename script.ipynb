{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67dd62c2-849a-4897-b145-8ab1b6ec23dc",
   "metadata": {},
   "source": [
    "# Improving Video Translation Quality with Large Language Models: A Look at Speech-to-Text Output Refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2700a15-d98d-41d4-bbc4-3dc6144c4460",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Solution Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfca4af-7ff2-4e5d-89dc-33f10070d697",
   "metadata": {},
   "source": [
    "<img src=\"./images/Arch_Diagram.jpg\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d170316c-56ef-4721-9dd7-6ef7abe820f6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbd55ee-b632-42fc-9679-cc853eb19d28",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Install Latest SDKs and import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05bf21a8-60f4-4596-ab9d-61effd30b6cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install openai --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f779dee-c2cc-4903-85d1-94092fd5de92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4554:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4554:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4554:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5033:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2501:(snd_pcm_open_noupdate) Unknown PCM default\n",
      "ALSA lib confmisc.c:767:(parse_card) cannot find card '0'\n",
      "ALSA lib conf.c:4554:(_snd_config_evaluate) function snd_func_card_driver returned error: No such file or directory\n",
      "ALSA lib confmisc.c:392:(snd_func_concat) error evaluating strings\n",
      "ALSA lib conf.c:4554:(_snd_config_evaluate) function snd_func_concat returned error: No such file or directory\n",
      "ALSA lib confmisc.c:1246:(snd_func_refer) error evaluating name\n",
      "ALSA lib conf.c:4554:(_snd_config_evaluate) function snd_func_refer returned error: No such file or directory\n",
      "ALSA lib conf.c:5033:(snd_config_expand) Evaluate error: No such file or directory\n",
      "ALSA lib pcm.c:2501:(snd_pcm_open_noupdate) Unknown PCM default\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import uuid\n",
    "import botocore\n",
    "import boto3\n",
    "import re\n",
    "import time\n",
    "import pprint\n",
    "import subprocess\n",
    "import json\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from datetime import datetime, timezone\n",
    "from pytube import YouTube\n",
    "from moviepy.editor import VideoFileClip\n",
    "import os\n",
    "import pysrt\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f27e53-f2c9-4175-a792-ba5c8e47e247",
   "metadata": {},
   "source": [
    "### Download Video and upload to S3\n",
    "Make sure all your resources are stored in the same region. You'll be using the same bucket for this entire walkthrough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e01dfbb6-0b4a-4338-81c5-4d13f94f188d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The S3 bucket used in this demo will be: sunil-video-translation\n"
     ]
    }
   ],
   "source": [
    "original_language_code = 'en-US'\n",
    "translated_language_code = 'hi'   \n",
    "def rename_file(old_name, new_name):\n",
    "    try:\n",
    "        os.rename(old_name, new_name)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error renaming file: {e}\")\n",
    "        return False\n",
    "    \n",
    "youtube_filename = \"%s__%s__%s.mp4\"%(str(uuid.uuid4()),original_language_code,translated_language_code)\n",
    "\n",
    "def download_video():   \n",
    "    if not os.path.isfile(youtube_filename):\n",
    "        yt = YouTube('https://www.youtube.com/watch?v=GhTC-pMgOjc&t=23s')\n",
    "        yt.streams.filter(progressive=True, file_extension='mp4').order_by('resolution').desc().first().download(filename=youtube_filename)\n",
    "    return youtube_filename\n",
    "\n",
    "video_filename = download_video()\n",
    "\n",
    "BUCKET = 'sunil-video-translation' #Add your bucket name here\n",
    "\n",
    "if(BUCKET==''):\n",
    "    BUCKET = sagemaker.Session().default_bucket()\n",
    "print(f'The S3 bucket used in this demo will be: {BUCKET}')\n",
    "\n",
    "OUTPUT_PATH_TRANSCRIBE = f's3://{BUCKET}/transcribe-results'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1a2eb9c-3d3d-434f-a749-57fbf9b0880e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b7b6b377-59a2-4e4c-b804-5104f905dd98__en-US__hi.mp4'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43663f6b",
   "metadata": {},
   "source": [
    "<img src=\"./images/Arch_Diagram_Step-1.jpg\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1631338-374c-4adc-9b7a-5806399de535",
   "metadata": {
    "tags": []
   },
   "source": [
    "### STEP-1 Separate Audio from Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb319e18-b1bb-490b-a105-edc0b48d3e52",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in b7b6b377-59a2-4e4c-b804-5104f905dd98__en-US__hi.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "audio_file_name = video_filename.replace(\".mp4\",\".wav\")\n",
    "videoclip = VideoFileClip(video_filename)\n",
    "if not os.path.isfile(audio_file_name):\n",
    "    videoclip.audio.write_audiofile(audio_file_name,ffmpeg_params=['-ac','1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfc6d16a-b31c-4866-8008-46f500ca11f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sess = sagemaker.session.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "# Amazon S3 (S3) client\n",
    "s3 = boto3.client('s3', region)\n",
    "bucket_region = s3.head_bucket(Bucket=BUCKET)['ResponseMetadata']['HTTPHeaders']['x-amz-bucket-region']\n",
    "assert bucket_region == region, \"Your S3 bucket {} and this notebook need to be in the same region.\".format(BUCKET)\n",
    "\n",
    "# Amazon SageMaker client\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "\n",
    "# Amazon Transcribe client\n",
    "transcribe_client = boto3.client(\"transcribe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba02e48-41b8-49d9-a6b4-23630762bf38",
   "metadata": {},
   "source": [
    "This is the execution role that will be used to call Amazon S3, Transcribe, Translate and Polly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddbe2dcc-a6a7-4f70-bf28-01992cc142d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arn:aws:iam::770763726637:role/service-role/AmazonSageMaker-ExecutionRole-20230808T082672'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "ROLE = get_execution_role()\n",
    "display(ROLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879f3814-7f96-4e51-af1c-f9dd64cd7d7f",
   "metadata": {},
   "source": [
    "Add the following policies to this role in IAM:\n",
    "* AmazonAugmentedAIFullAccess\n",
    "* AmazonTranscribeFullAccess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d714e79-9b64-4a1f-9d6f-e7dba8a18a2f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b7b6b377-59a2-4e4c-b804-5104f905dd98__en-US__hi.wav'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_file_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7fdda69-0d2b-41a8-b428-56b86cc26458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: cannot remove ‘/tmp/*.wav’: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: audio_files/b7b6b377-59a2-4e4c-b804-5104f905dd98__en-US__hi.wav to s3://sunil-video-translation/es_conf_transcribe_demo/b7b6b377-59a2-4e4c-b804-5104f905dd98__en-US__hi.wav\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$BUCKET\"\n",
    "rm /tmp/*.json\n",
    "rm /tmp/*.wav\n",
    "rm /tmp/*.srt\n",
    "mkdir audio_files\n",
    "mv *.wav audio_files\n",
    "aws s3 cp ./audio_files s3://$1/es_conf_transcribe_demo/ --recursive\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d620ad86-5e36-4df2-b5e3-715dbda0a263",
   "metadata": {},
   "source": [
    "### STEP-2 Transcribe the Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76208fb",
   "metadata": {},
   "source": [
    "<img src=\"./images/Arch_Diagram_Step-2.jpg\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a63b378-34bd-4553-a3b6-66f1b4027cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is a transcribe function\n",
    "def transcribe(job_name, job_uri, out_bucket, format=\"wav\", vocab_name=None):\n",
    "    \"\"\"Transcribe a .wav or .mp4 file to text.\n",
    "    Args:\n",
    "        job_name (str): the name of the job that you specify;\n",
    "                        the output json will be job_name.json\n",
    "        job_uri (str): input path (in s3) to the file being transcribed\n",
    "        out_bucket (str): s3 bucket name that you want the output json\n",
    "                          to be placed in\n",
    "        format (str): mp4 or wav for input file format;\n",
    "                      defaults to mp4\n",
    "        vocab_name (str): name of custom vocabulary used;\n",
    "                          optional, defaults to None\n",
    "    \"\"\"\n",
    "    \n",
    "    if format not in ['mp3','mp4','wav','flac']:\n",
    "        print(\"Invalid format\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        \n",
    "        transcribe_client.start_transcription_job(\n",
    "            TranscriptionJobName=job_name,\n",
    "            Media={\"MediaFileUri\": job_uri},\n",
    "            MediaFormat=format,\n",
    "            LanguageCode=\"en-US\",\n",
    "            OutputBucketName=out_bucket,\n",
    "            Subtitles = {\n",
    "                'Formats': [\n",
    "                    'srt'\n",
    "                ],\n",
    "                'OutputStartIndex': 1 \n",
    "            }\n",
    "        )        \n",
    "        time.sleep(2)        \n",
    "        print(transcribe_client.get_transcription_job(TranscriptionJobName=job_name))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00095231-3524-4a76-9884-4187ccc54aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TranscriptionJob': {'TranscriptionJobName': 'b7b6b377-59a2-4e4c-b804-5104f905dd98__en-US__hi', 'TranscriptionJobStatus': 'IN_PROGRESS', 'LanguageCode': 'en-US', 'MediaFormat': 'wav', 'Media': {'MediaFileUri': 's3://sunil-video-translation/es_conf_transcribe_demo/b7b6b377-59a2-4e4c-b804-5104f905dd98__en-US__hi.wav'}, 'Transcript': {}, 'StartTime': datetime.datetime(2023, 9, 12, 20, 11, 25, 210000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2023, 9, 12, 20, 11, 25, 179000, tzinfo=tzlocal()), 'Settings': {'ChannelIdentification': False, 'ShowAlternatives': False}, 'Subtitles': {'Formats': ['srt'], 'SubtitleFileUris': []}}, 'ResponseMetadata': {'RequestId': 'ca193fff-4287-4cb4-bbdf-56c816e83bd7', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'ca193fff-4287-4cb4-bbdf-56c816e83bd7', 'content-type': 'application/x-amz-json-1.1', 'content-length': '507', 'date': 'Tue, 12 Sep 2023 20:11:26 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "# Path to folder\n",
    "\n",
    "folder_path = f\"s3://{BUCKET}/es_conf_transcribe_demo/\"\n",
    "job_name = audio_file_name.rsplit('.',1)[0]\n",
    "job_name\n",
    "time.sleep(2)\n",
    "transcribe(job_name, folder_path+audio_file_name, BUCKET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3190a923-32d4-4059-b0e1-1df853853b71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "Not ready yet...\n",
      "COMPLETED\n"
     ]
    }
   ],
   "source": [
    "# Wait for the status of the transcription job to finish\n",
    "while True:\n",
    "    response = transcribe_client.get_transcription_job(\n",
    "        TranscriptionJobName=job_name \n",
    "    )\n",
    "    status = response['TranscriptionJob']['TranscriptionJobStatus']\n",
    "    if status in ['COMPLETED', 'FAILED']:\n",
    "        print(status)\n",
    "        break\n",
    "    print(\"Not ready yet...\")\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be6e876b-07c0-43d9-9832-845c17b21bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the two S3 buckets below\n",
    "bucket_name_original_srt = \"sunil-video-translation-output-original-srt\"\n",
    "bucket_name_translated_srt = \"sunil-video-translation-output-translated-srt\"\n",
    "\n",
    "# time duration threshold to split transcribed text to subtitles. 0.05 is 50 milliseconds\n",
    "time_duration_threshold = 0.2\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "openai.organization = \"\"\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71999fe5-0563-48b1-acef-bf56bd2f11da",
   "metadata": {},
   "source": [
    "### STEP-3 Text Correction via LLM API call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9e2117",
   "metadata": {},
   "source": [
    "<img src=\"./images/Arch_Diagram_Step-3.jpg\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d5f0222-5c60-41c7-8c84-77a273d75d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_api(prompt):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model='gpt-4',\n",
    "        messages=prompt\n",
    "    )\n",
    "    message = response.choices[0].message.content.strip()\n",
    "    return message\n",
    "\n",
    "def fix_text(text):\n",
    "    user_prompt = []\n",
    "    user_prompt.append({'role':'system', 'content':'I will provide a sentence about AWS Well-Architected. Correct the sentence. If the sentence is correct or incomplete, just return the same sentence'})\n",
    "    user_prompt.append({'role':'user', 'content': text})\n",
    "    api_response = call_api(user_prompt)\n",
    "    return api_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee778d0",
   "metadata": {},
   "source": [
    "### STEP-4 Translate Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ece360",
   "metadata": {},
   "source": [
    "<img src=\"./images/Arch_Diagram_Step-4.jpg\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aba1d9f7-3a3b-4f2c-9e0e-8cb5286d716c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Amazon Translate client\n",
    "translate = boto3.client(service_name='translate')\n",
    "\n",
    "# Pass in seconds with millisecond value. Eg: 73.045 and output is in 00:01:13,045 (SRT format)\n",
    "def format_time(seconds):\n",
    "    sec = timedelta(seconds=seconds)\n",
    "    d = datetime(1,1,1) + sec\n",
    "    s = d.strftime(\"%H:%M:%S,%f\")\n",
    "    return str(s[:-3])\n",
    "\n",
    "def translate_text(text,source_language_code,target_language_code):\n",
    "    if source_language_code == target_language_code:\n",
    "        return text\n",
    "    else:\n",
    "        result = translate.translate_text(Text=text, \n",
    "            SourceLanguageCode=source_language_code, TargetLanguageCode=target_language_code)\n",
    "        return result.get('TranslatedText')\n",
    "\n",
    "def save_original_and_translated(json_file_name,source_language_code,target_language_code):\n",
    "    #print(\"Working with json_file_name: \",json_file_name)\n",
    "    with open(json_file_name) as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    Tuple_list=[]\n",
    "        \n",
    "    for word in data['results']['items']:\n",
    "        if word['type'] != 'punctuation':\n",
    "            current_word = str(word['alternatives'][0]['content'])\n",
    "            start_time = float(word['start_time'])\n",
    "            end_time = float(word['end_time'])\n",
    "            confidence_value = float(word['alternatives'][0]['confidence'])\n",
    "            if len(Tuple_list)==0:\n",
    "                Tuple_list.append([current_word,start_time,end_time])\n",
    "            else:\n",
    "                last_item = Tuple_list.pop()\n",
    "                old_word = last_item[0]\n",
    "                old_start_time = last_item[1]\n",
    "                old_end_time = last_item[2]\n",
    "                old_duration = old_end_time - old_start_time\n",
    "                \n",
    "                if (start_time - old_end_time) > time_duration_threshold or old_word.endswith('.') :\n",
    "                    Tuple_list.append(last_item)\n",
    "                    Tuple_list.append([current_word,start_time,end_time])\n",
    "                else:\n",
    "                    current_word = old_word+' '+current_word\n",
    "                    start_time = old_start_time\n",
    "                    Tuple_list.append([current_word,start_time,end_time])\n",
    "        else:\n",
    "            last_item = Tuple_list.pop()\n",
    "            old_word = last_item[0]+str(word['alternatives'][0]['content'])\n",
    "            old_start_time = last_item[1]\n",
    "            old_end_time = last_item[2]\n",
    "            Tuple_list.append([old_word,old_start_time,old_end_time])\n",
    "                    \n",
    "    srt_filename_original = json_file_name.replace(\".json\",\"_original.srt\")\n",
    "    srt_filename_translated = json_file_name.replace(\".json\",\"_translated.srt\")\n",
    "    \n",
    "    index=1\n",
    "    with open(srt_filename_original,\"w\") as f1,open(srt_filename_translated,\"w\") as f2 :\n",
    "        for item in Tuple_list:\n",
    "            start = item[1]\n",
    "            end = item[2]\n",
    "            original_text = item[0]\n",
    "            fixed_text = fix_text(original_text)\n",
    "            # file 1\n",
    "            f1.write(str(index))\n",
    "            f1.write(\"\\n\")\n",
    "            f1.write(format_time(start))\n",
    "            f1.write(' --> '),\n",
    "            f1.write(format_time(end))\n",
    "            f1.write(\"\\n\")\n",
    "            f1.write(fixed_text)\n",
    "            f1.write(\"\\n\\n\")\n",
    "            # file 2\n",
    "            f2.write(str(index))\n",
    "            f2.write(\"\\n\")\n",
    "            f2.write(format_time(start))\n",
    "            f2.write(' --> '),\n",
    "            f2.write(format_time(end))\n",
    "            f2.write(\"\\n\")\n",
    "            translated_text = translate_text(fixed_text,source_language_code,target_language_code)\n",
    "            # translated_text = translate_text(original_text,source_language_code,target_language_code)\n",
    "            f2.write(translated_text)\n",
    "            f2.write(\"\\n\\n\")\n",
    "            \n",
    "            index = index+1\n",
    "            print(original_text)\n",
    "            print(fixed_text)\n",
    "            print(translated_text)\n",
    "    \n",
    "    basefilename_original = os.path.basename(srt_filename_original)\n",
    "    s3.upload_file(srt_filename_original, bucket_name_original_srt, basefilename_original)\n",
    "    \n",
    "    print(\"uploaded original: \",basefilename_original)\n",
    "\n",
    "    basefilename_translated = os.path.basename(srt_filename_translated)\n",
    "    s3.upload_file(srt_filename_translated, bucket_name_translated_srt, basefilename_translated)\n",
    "    \n",
    "    print(\"uploaded translated: \",basefilename_translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce5cfe50-6a2a-48ef-adc5-ca5344270445",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename  b7b6b377-59a2-4e4c-b804-5104f905dd98__en-US__hi.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['.ICE-unix',\n",
       " '.font-unix',\n",
       " '.X11-unix',\n",
       " '.Test-unix',\n",
       " '.XIM-unix',\n",
       " 'b7b6b377-59a2-4e4c-b804-5104f905dd98__en-US__hi.json',\n",
       " 'b7b6b377-59a2-4e4c-b804-5104f905dd98__en-US__hi_original.srt',\n",
       " 'b7b6b377-59a2-4e4c-b804-5104f905dd98__en-US__hi_translated.srt',\n",
       " 'systemd-private-cac83c6dc8e74a988e2e2613351323cf-chronyd.service-MiVOkD',\n",
       " 'hsperfdata_role-agent',\n",
       " 'ffmpeg.linux64',\n",
       " '.java_pid3683']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file_name = job_name+'.json'\n",
    "output_file_path = '/tmp/'+json_file_name\n",
    "print (\"Filename \",json_file_name)\n",
    "s3.download_file(BUCKET,json_file_name, output_file_path)\n",
    "os.listdir('/tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f924d5f-9cc2-4bf7-b666-eea3ca6fb8c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source_language_code:  en\n",
      "target_language_code:  hi\n"
     ]
    }
   ],
   "source": [
    "base_filename_json = json_file_name.rsplit('.',1)[0]\n",
    "language_string = base_filename_json.rsplit(\"__\",2)\n",
    "source_language_code = language_string[-2].split('-')[0].lower()\n",
    "target_language_code= language_string[-1].lower()\n",
    "    \n",
    "print(\"source_language_code: \",source_language_code)\n",
    "print(\"target_language_code: \",target_language_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "702e5427-5970-43bf-9c7b-5c9ab0933f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello and welcome to this five minute overview of Aws.\n",
      "Hello and welcome to this five minute overview of AWS Well-Architected.\n",
      "नमस्कार और AWS Well-Architected के इस पांच मिनट के अवलोकन में आपका स्वागत है।\n",
      "Well, Architected,\n",
      "Well-Architected.\n",
      "अच्छी तरह से तैयार किया गया।\n",
      "I am Mark Isaacs senior startup solution architect at Aws.\n",
      "I am Mark Isaacs, Senior Startup Solutions Architect at AWS.\n",
      "मैं मार्क इसाक, एडब्ल्यूएस में सीनियर स्टार्टअप सॉल्यूशंस आर्किटेक्ट हूं।\n",
      "Today, I will be giving you an overview of Aws well architected, what it is and how it can help you.\n",
      "Today, I will be giving you an overview of AWS Well-Architected, what it is, and how it can help you.\n",
      "आज, मैं आपको AWS Well-Architected का अवलोकन दूंगा कि यह क्या है, और यह आपकी मदद कैसे कर सकता है।\n",
      "So why does Aws Well, architecture exist?\n",
      "So why does AWS Well-Architected exist?\n",
      "तो AWS वेल-आर्किटेक्टेड क्यों मौजूद है?\n",
      "Aws solution architects have years of experience working with customers,\n",
      "AWS solution architects have years of experience working with customers.\n",
      "AWS समाधान आर्किटेक्ट के पास ग्राहकों के साथ काम करने का वर्षों का अनुभव है।\n",
      "architect solutions across a wide variety of workloads and use cases.\n",
      "Architect solutions across a wide variety of workloads and use cases.\n",
      "विभिन्न प्रकार के वर्कलोड और उपयोग के मामलों में आर्किटेक्ट समाधान।\n",
      "We have helped design and review thousands of customers architectures on Aws.\n",
      "We have helped design and review thousands of customer architectures on AWS.\n",
      "हमने AWS पर हजारों ग्राहक आर्किटेक्चर को डिज़ाइन करने और उनकी समीक्षा करने में मदद की है।\n",
      "From this experience, we have helped customers identify\n",
      "From this experience, we have helped customers identify.\n",
      "इस अनुभव से, हमने ग्राहकों को पहचानने में मदद की है।\n",
      "best practices and core strategies to help them understand the pros and cons of decisions they make while building systems on Aws.\n",
      "Best practices and core strategies are provided by AWS Well-Architected to help users understand the pros and cons of decisions they make while building systems on AWS.\n",
      "AWS Well-Architected द्वारा उपयोगकर्ताओं को AWS पर सिस्टम बनाते समय किए जाने वाले निर्णयों के फायदे और नुकसान को समझने में मदद करने के लिए सर्वोत्तम अभ्यास और मुख्य रणनीतियां प्रदान की जाती हैं।\n",
      "Aws.\n",
      "AWS.\n",
      "एडब्ल्यूएस।\n",
      "Well, architected helps cloud architects build secure, high performing resilient and efficient infrastructure for their applications and workloads.\n",
      "Well-Architected helps cloud architects build secure, high-performing, resilient, and efficient infrastructure for their applications and workloads.\n",
      "अच्छी तरह से तैयार किया गया क्लाउड आर्किटेक्ट को उनके अनुप्रयोगों और कार्यभार के लिए सुरक्षित, उच्च प्रदर्शन करने वाला, लचीला और कुशल बुनियादी ढांचा बनाने में मदद करता है।\n",
      "It is more than a tool.\n",
      "It is more than a tool.\n",
      "यह एक उपकरण से बढ़कर है।\n",
      "Well, architected is a mechanism for your cloud journey.\n",
      "Well-Architected is a framework for your cloud journey.\n",
      "वेल-आर्किटेक्टेड आपकी क्लाउड यात्रा के लिए एक ढांचा है।\n",
      "It allows you to learn the strategies and best practices for architect in the cloud, measure your architecture against best practices using the well architected tool and improve architectures by addressing any high risk issues identified\n",
      "It allows you to learn the strategies and best practices for architecture in the cloud, measure your architecture against best practices using the Well-Architected tool, and improve architectures by addressing any high-risk issues identified.\n",
      "यह आपको क्लाउड में आर्किटेक्चर के लिए रणनीतियों और सर्वोत्तम प्रथाओं को सीखने, वेल-आर्किटेक्चर टूल का उपयोग करके सर्वोत्तम प्रथाओं के खिलाफ अपने आर्किटेक्चर को मापने और पहचाने गए किसी भी उच्च जोखिम वाले मुद्दों को हल करके आर्किटेक्चर में सुधार करने की अनुमति देता है।\n",
      "as a startup.\n",
      "As a startup.\n",
      "स्टार्टअप के रूप में।\n",
      "You want to minimize the risk of one way decisions early in your design process.\n",
      "You want to minimize the risk of one-way decisions early in your design process.\n",
      "आप अपनी डिज़ाइन प्रक्रिया की शुरुआत में एकतरफ़ा निर्णयों के जोखिम को कम करना चाहते हैं।\n",
      "It helps you better gauge the state of your architecture and create improvement road maps to incorporate into your plans.\n",
      "It helps you better gauge the state of your architecture and create improvement roadmaps to incorporate into your plans.\n",
      "यह आपकी वास्तुकला की स्थिति का बेहतर आकलन करने और अपनी योजनाओं में शामिल करने के लिए सुधार रोडमैप बनाने में आपकी मदद करता है।\n",
      "The well architected framework provides a set of questions and design principles across five pillars.\n",
      "The AWS Well-Architected Framework provides a set of questions and design principles across five pillars.\n",
      "AWS वेल-आर्किटेक्टेड फ्रेमवर्क पांच स्तंभों में प्रश्नों और डिजाइन सिद्धांतों का एक सेट प्रदान करता है।\n",
      "The five pillars forms the foundation for building well architected solutions or workloads on Aws.\n",
      "The five pillars form the foundation for building well-architected solutions or workloads on AWS.\n",
      "पांच स्तंभ AWS पर अच्छी तरह से तैयार किए गए समाधान या वर्कलोड बनाने की नींव बनाते हैं।\n",
      "Let's look at what these five pillars are.\n",
      "Let's look at what these five pillars are.\n",
      "आइए देखें कि ये पांच स्तंभ क्या हैं।\n",
      "When you incorporate these pillars, it will help you produce stable and efficient systems allowing you to focus on functional requirements.\n",
      "When you incorporate the five pillars of AWS Well-Architected Framework, it will help you produce stable and efficient systems allowing you to focus on functional requirements.\n",
      "जब आप AWS वेल-आर्किटेक्टेड फ्रेमवर्क के पांच स्तंभों को शामिल करते हैं, तो यह आपको स्थिर और कुशल सिस्टम बनाने में मदद करेगा, जिससे आप कार्यात्मक आवश्यकताओं पर ध्यान केंद्रित कर सकेंगे।\n",
      "The operational excellence pillar focuses on running and monitoring systems to deliver business value and continue improving processes and procedures.\n",
      "The operational excellence pillar focuses on running and monitoring systems to deliver business value and continuously improving processes and procedures.\n",
      "परिचालन उत्कृष्टता स्तंभ व्यावसायिक मूल्य प्रदान करने और प्रक्रियाओं और प्रक्रियाओं में निरंतर सुधार करने के लिए सिस्टम चलाने और निगरानी करने पर केंद्रित है।\n",
      "Key topics include automating changes, responding to events and defining standards to manage your daily operations.\n",
      "Key topics include automating changes, responding to events, and defining standards to manage your daily operations.\n",
      "मुख्य विषयों में परिवर्तनों को स्वचालित करना, ईवेंट पर प्रतिक्रिया देना और अपने दैनिक कार्यों को प्रबंधित करने के लिए मानकों को परिभाषित करना शामिल है।\n",
      "The security pillar focuses on protecting information and systems.\n",
      "The sentence is correct.\n",
      "वाक्य सही है।\n",
      "Key topics include confidentiality and integrity of data,\n",
      "Key topics include confidentiality and integrity of data.\n",
      "मुख्य विषयों में डेटा की गोपनीयता और अखंडता शामिल है।\n",
      "identifying and managing who can do what with privilege management,\n",
      "Identifying and managing who can do what with privilege management.\n",
      "विशेषाधिकार प्रबंधन के साथ कौन क्या कर सकता है, इसकी पहचान करना और प्रबंधन करना।\n",
      "protecting systems and establishing controls to detect security events.\n",
      "Protecting systems and establishing controls to detect security events.\n",
      "सुरक्षा घटनाओं का पता लगाने के लिए सिस्टम की सुरक्षा करना और नियंत्रण स्थापित करना।\n",
      "The reliability pillar focuses on ensuring the workload performs its intended function correctly and consistently when it's expected to\n",
      "The reliability pillar focuses on ensuring the workload performs its intended function correctly and consistently when it's expected to.\n",
      "विश्वसनीयता स्तंभ यह सुनिश्चित करने पर ध्यान केंद्रित करता है कि कार्यभार अपने इच्छित कार्य को सही ढंग से और लगातार करता है, जब इसकी अपेक्षा की जाती है।\n",
      "a resilient, workload, quickly recovers from failures to meet business and customer demand.\n",
      "A resilient workload quickly recovers from failures to meet business and customer demand.\n",
      "एक लचीला कार्यभार व्यवसाय और ग्राहकों की मांग को पूरा करने में विफलताओं से जल्दी ठीक हो जाता है।\n",
      "Key topics include distributed system design,\n",
      "Key topics include distributed system design.\n",
      "मुख्य विषयों में वितरित सिस्टम डिज़ाइन शामिल है।\n",
      "recovery planning and how to handle change.\n",
      "recovery planning and how to handle change.\n",
      "पुनर्प्राप्ति योजना और परिवर्तन को कैसे संभालना है।\n",
      "The performance efficiency pillar focuses on using it and computing resources efficiently.\n",
      "The performance efficiency pillar focuses on using computing resources efficiently.\n",
      "प्रदर्शन दक्षता स्तंभ कंप्यूटिंग संसाधनों का कुशलतापूर्वक उपयोग करने पर केंद्रित है।\n",
      "Key topics include selecting the right resource types and sizes based on workload requirements,\n",
      "Key topics include selecting the right resource types and sizes based on workload requirements.\n",
      "मुख्य विषयों में कार्यभार आवश्यकताओं के आधार पर सही संसाधन प्रकारों और आकारों का चयन करना शामिल है।\n",
      "monitoring performance and making informed decisions to maintain efficiency as business needs evolve.\n",
      "Monitoring performance and making informed decisions to maintain efficiency as business needs evolve.\n",
      "व्यवसाय की ज़रूरतें विकसित होने पर दक्षता बनाए रखने के लिए प्रदर्शन की निगरानी करना और सूचित निर्णय लेना।\n",
      "The cost optimization pillar focuses on avoiding unnecessary costs.\n",
      "The cost optimization pillar focuses on avoiding unnecessary costs.\n",
      "लागत अनुकूलन स्तंभ अनावश्यक लागतों से बचने पर केंद्रित है।\n",
      "Key topics include understanding and controlling where money is being spent,\n",
      "Key topics include understanding and controlling where money is being spent.\n",
      "मुख्य विषयों में यह समझना और नियंत्रित करना शामिल है कि पैसा कहाँ खर्च किया जा रहा है।\n",
      "selecting the most appropriate and right number of resource types,\n",
      "Selecting the most appropriate and right number of resource types.\n",
      "संसाधनों के प्रकारों की सबसे उपयुक्त और सही संख्या का चयन करना।\n",
      "analyzing spend over time\n",
      "Analyzing spend over time.\n",
      "समय के साथ खर्च का विश्लेषण करना।\n",
      "and scaling to meet business needs without overspending\n",
      "and scaling to meet business needs without overspending.\n",
      "और अधिक खर्च किए बिना व्यावसायिक जरूरतों को पूरा करने के लिए स्केलिंग।\n",
      "the Aws.\n",
      "The AWS.\n",
      "एडब्ल्यूएस।\n",
      "Well architected lenses extend the guidance offered by Aws.\n",
      "Well-Architected Lenses extend the guidance offered by AWS.\n",
      "अच्छी तरह से तैयार किए गए लेंस AWS द्वारा दिए गए मार्गदर्शन का विस्तार करते हैं।\n",
      "Well architected to specific industry and technology domains such as serverless applications, foundational technical review and SAS lenses are offered within the well architected tool\n",
      "Specific industry and technology domains such as serverless applications, foundational technical review, and SaaS lenses are offered within the AWS Well-Architected Tool.\n",
      "AWS वेल-आर्किटेक्चर टूल के भीतर विशिष्ट उद्योग और प्रौद्योगिकी डोमेन जैसे सर्वर रहित एप्लिकेशन, मूलभूत तकनीकी समीक्षा और SaaS लेंस की पेशकश की जाती है।\n",
      "to fully evaluate your workloads, use applicable lenses together with the Aws well architected framework and the five pillars.\n",
      "To fully evaluate your workloads, use applicable lenses together with the AWS Well-Architected Framework and the five pillars.\n",
      "अपने वर्कलोड का पूरी तरह से मूल्यांकन करने के लिए, AWS वेल-आर्किटेक्टेड फ्रेमवर्क और पांच स्तंभों के साथ लागू लेंस का उपयोग करें।\n",
      "We use the well architected tool in the console.\n",
      "We use the Well-Architected Tool in the console.\n",
      "हम कंसोल में वेल-आर्किटेड टूल का उपयोग करते हैं।\n",
      "When executing the well architected process on a selected workload,\n",
      "When executing the Well-Architected process on a selected workload,\n",
      "चयनित कार्यभार पर अच्छी तरह से तैयार की गई प्रक्रिया को निष्पादित करते समय,\n",
      "all details are stored securely in your Aws account.\n",
      "All details are stored securely in your AWS account.\n",
      "सभी विवरण आपके AWS खाते में सुरक्षित रूप से संग्रहीत हैं।\n",
      "Workloads can be shared with your essay or partner resource for collaboration on the review or remediation steps using workload, sharing.\n",
      "Workloads can be shared with your team or partner resource for collaboration on the review or remediation steps using workload sharing.\n",
      "वर्कलोड शेयरिंग का उपयोग करके समीक्षा या सुधार चरणों पर सहयोग के लिए वर्कलोड को आपकी टीम या पार्टनर संसाधन के साथ साझा किया जा सकता है।\n",
      "The well architected tool also has an api for programmatic access.\n",
      "The Well-Architected Tool also has an API for programmatic access.\n",
      "वेल-आर्किटेक्टेड टूल में प्रोग्रामेटिक एक्सेस के लिए एक एपीआई भी है।\n",
      "The architecture health needs to be done in a consistent manner with a blame free approach that encourages diving deep.\n",
      "The assessment of architectural health needs to be conducted in a consistent manner with a blame-free approach that encourages deep diving.\n",
      "वास्तु स्वास्थ्य का आकलन एक दोष-मुक्त दृष्टिकोण के साथ सुसंगत तरीके से किया जाना चाहिए जो गहन गोताखोरी को प्रोत्साहित करता है।\n",
      "It should be a lightweight process hours, not days.\n",
      "It should be a lightweight process taking hours, not days.\n",
      "यह एक हल्की प्रक्रिया होनी चाहिए जिसमें घंटों लगते हैं, दिन नहीं।\n",
      "That is a conversation and not an audit.\n",
      "This is a conversation and not an audit.\n",
      "यह बातचीत है न कि ऑडिट।\n",
      "The purpose of reviewing an architecture is to identify any critical issues that might need addressing or areas that could be improved.\n",
      "The purpose of reviewing an architecture is to identify any critical issues that might need addressing or areas that could be improved.\n",
      "आर्किटेक्चर की समीक्षा करने का उद्देश्य उन महत्वपूर्ण मुद्दों की पहचान करना है जिन्हें संबोधित करने की आवश्यकता हो सकती है या जिन क्षेत्रों में सुधार किया जा सकता है।\n",
      "The outcome of the process is a set of actions that should improve the experience of a customer using the workload.\n",
      "The outcome of the process is a set of actions that should improve the experience of a customer using the workload.\n",
      "प्रक्रिया का परिणाम क्रियाओं का एक समूह है, जिससे कार्यभार का उपयोग करने वाले ग्राहक के अनुभव में सुधार होना चाहिए।\n",
      "As always the earlier you do this in your cloud journey, the more you improve your chances of success and limit technical debt.\n",
      "As always, the earlier you do this in your cloud journey, the more you improve your chances of success and limit technical debt.\n",
      "हमेशा की तरह, आप अपनी क्लाउड यात्रा में जितनी जल्दी ऐसा करते हैं, उतना ही आप अपनी सफलता की संभावनाओं में सुधार करते हैं और तकनीकी ऋण को सीमित करते हैं।\n",
      "So when should you do a deep dive into your architecture.\n",
      "When should you do a deep dive into your architecture?\n",
      "आपको अपनी वास्तुकला में गहरा गोता कब लगाना चाहिए?\n",
      "Health\n",
      "Health\n",
      "हेल्थ\n",
      "health checks should be applied at key milestones in your product or application life cycle\n",
      "Health checks should be applied at key milestones in your product or application lifecycle.\n",
      "आपके उत्पाद या अनुप्रयोग जीवनचक्र में महत्वपूर्ण मील के पत्थर पर स्वास्थ्य जांच लागू की जानी चाहिए।\n",
      "early on in the design phase to avoid decisions that are difficult to change.\n",
      "early on in the design phase to avoid decisions that are difficult to change.\n",
      "उन निर्णयों से बचने के लिए जिन्हें बदलना मुश्किल है, डिज़ाइन चरण की शुरुआत में।\n",
      "And then before the go live date,\n",
      "And then before the go live date,\n",
      "और फिर गो लाइव डेट से पहले,\n",
      "as a startup, you need a performance, secure reliable product.\n",
      "As a startup, you need a performance-efficient, secure, and reliable product.\n",
      "एक स्टार्टअप के रूप में, आपको एक प्रदर्शन-कुशल, सुरक्षित और विश्वसनीय उत्पाद की आवश्यकता होती है।\n",
      "Before you go live,\n",
      "Before you go live,\n",
      "इससे पहले कि आप लाइव हो जाएं,\n",
      "you don't want to damage your brand before you even get a chance to build it.\n",
      "You don't want to damage your brand before you even get a chance to build it.\n",
      "इससे पहले कि आपको इसे बनाने का मौका मिले, आप अपने ब्रांड को नुकसान नहीं पहुंचाना चाहते हैं।\n",
      "Therefore, the recommended approach is to do it early in your product life cycle and continuously as key aspects of your architecture change, you want it to become part of your DNA to build well architected solutions.\n",
      "Therefore, the recommended approach is to integrate it early in your product life cycle and continuously adapt as key aspects of your architecture change. You want it to become part of your DNA to build well-architected solutions.\n",
      "इसलिए, अनुशंसित दृष्टिकोण यह है कि इसे अपने उत्पाद जीवन चक्र में जल्दी एकीकृत किया जाए और अपने आर्किटेक्चर परिवर्तन के प्रमुख पहलुओं के रूप में लगातार अनुकूलित किया जाए। आप चाहते हैं कि यह आपके DNA का हिस्सा बने, ताकि अच्छी तरह से तैयार किए गए समाधान तैयार किए जा सकें।\n",
      "Thank you for listening to this episode and keep watching this series as we dive deep into each of the well architected pillars.\n",
      "Thank you for listening to this episode and keep watching this series as we dive deep into each of the AWS Well-Architected pillars.\n",
      "इस एपिसोड को सुनने के लिए धन्यवाद और इस श्रृंखला को देखते रहें क्योंकि हम AWS वेल-आर्किटेक्टेड स्तंभों में से प्रत्येक में गहराई से गोता लगाते हैं।\n",
      "uploaded original:  b7b6b377-59a2-4e4c-b804-5104f905dd98__en-US__hi_original.srt\n",
      "uploaded translated:  b7b6b377-59a2-4e4c-b804-5104f905dd98__en-US__hi_translated.srt\n"
     ]
    }
   ],
   "source": [
    "# Convert transcribed json to a subtitle (srt) file.\n",
    "save_original_and_translated(output_file_path,source_language_code,target_language_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67269ad-933a-468b-b251-261611915335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import stat\n",
    "from pysrt import srtitem\n",
    "from pyssml.AmazonSpeech import AmazonSpeech\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6611327e-91fd-447b-98b9-dc50cc34b313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "polly = boto3.client(\"polly\")\n",
    "l_tmp_dir = '/tmp' # Lambda fuction can use this directory.\n",
    "# ffmpeg is stored with this script.\n",
    "# When executing ffmpeg, execute permission is requierd.\n",
    "# But Lambda source directory do not have permission to change it.\n",
    "# So move ffmpeg binary to `/tmp` and add permission.\n",
    "print (\"Files before \",os.listdir(l_tmp_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915870e-d9e5-4c85-80ee-226a8a851a79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ffmpeg_bin = \"{0}/ffmpeg.linux64\".format(l_tmp_dir)\n",
    "shutil.copyfile('ffmpeg.linux64', ffmpeg_bin)\n",
    "os.environ['IMAGEIO_FFMPEG_EXE'] = ffmpeg_bin\n",
    "os.chmod(ffmpeg_bin, os.stat(ffmpeg_bin).st_mode | stat.S_IEXEC)\n",
    "\n",
    "print (\"Files after \",os.listdir(l_tmp_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722be3be-1558-4593-a6ae-ef14ca418ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from moviepy.config import change_settings\n",
    "change_settings({\"FFMPEG_BINARY\": ffmpeg_bin})\n",
    "\n",
    "\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "525203be-8793-46a3-8fef-5f1f26809586",
   "metadata": {},
   "source": [
    "### STEP-5 Generate Audio from translated text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b898b5e2",
   "metadata": {},
   "source": [
    "<img src=\"./images/Arch_Diagram_Step-5.jpg\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646247a7-6659-4d46-8ced-77d3f4d35783",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "  # Voices https://docs.aws.amazon.com/polly/latest/dg/voicelist.html\n",
    "voiceid_list = {\n",
    "    \n",
    "    \"en\" : \"Aditi\",\n",
    "    \"fr\" : \"Mathieu\",\n",
    "    \"es\" : \"Miguel\",\n",
    "    \"ru\" : \"Maxim\",\n",
    "    \"zh\" : \"Zhiyu\",\n",
    "    \"ja\" : \"izuki\",\n",
    "    \"pt\" : \"Ricardo\",\n",
    "    \"de\" : \"Marlene\",\n",
    "    \"it\" : \"carla\",\n",
    "    \"tr\" : \"Filiz\",\n",
    "    \"hi\" : \"Aditi\"\n",
    "}\n",
    "\n",
    "from pydub import AudioSegment\n",
    "AudioSegment.converter = ffmpeg_bin\n",
    "\n",
    "def get_milli_seconds(timecode):\n",
    "    return (timecode.hours * 3600000 + timecode.minutes * 60000 \\\n",
    "    + timecode.seconds * 1000 + timecode.milliseconds)\n",
    "\n",
    "def write_mp3_files(filename_translated,voice_id):\n",
    "    \n",
    "    translated_subs = pysrt.open(filename_translated,encoding='utf-8')\n",
    "\n",
    "    for index,each in enumerate(translated_subs):\n",
    "        subtitle_index = index+1\n",
    "        content = each.text\n",
    "        print (subtitle_index)\n",
    "        print (content)\n",
    "        \n",
    "        time_duration = each.duration\n",
    "        time_duration_milliseconds = get_milli_seconds(time_duration)\n",
    "        # Add some buffer to time duration just to accomodate beginning and end\n",
    "        time_duration_milliseconds = time_duration_milliseconds + 250\n",
    "        time_duration_string = str(time_duration_milliseconds)+\"ms\"\n",
    "        ssml= \"<speak><prosody amazon:max-duration='\"+ time_duration_string +\"'>\" + content + \"</prosody></speak>\"\n",
    "        \n",
    "        response = polly.synthesize_speech(\n",
    "            OutputFormat='mp3',\n",
    "            Text=ssml,\n",
    "            TextType ='ssml',\n",
    "            VoiceId=voice_id,     \n",
    "        )\n",
    "\n",
    "        body = response['AudioStream'].read()\n",
    "        append_string = '__'+str(subtitle_index)+'.mp3'\n",
    "        mp3filename = filename_translated.replace('.srt',append_string)\n",
    "        wavfilename = mp3filename.replace('.mp3','.wav')\n",
    "        \n",
    "        with open(mp3filename,'wb') as file:\n",
    "            file.write(body)\n",
    "            file.close()\n",
    "            \n",
    "        translated_wavfilename = AudioFileClip(mp3filename)\n",
    "        translated_wavfilename.write_audiofile(wavfilename,ffmpeg_params=['-ac','1'])\n",
    "        \n",
    "        os.remove(mp3filename)    \n",
    "\n",
    "\n",
    "def save_voice_muted_audio_file(filename_translated,original_audio):\n",
    "    translated_subs = pysrt.open(filename_translated,encoding='utf-8')\n",
    "    for index,each in enumerate(translated_subs):\n",
    "        subtitle_index = index+1\n",
    "        content = each.text\n",
    "        current_start = get_milli_seconds(each.start)\n",
    "        current_end = get_milli_seconds(each.end)\n",
    "        previous_end = get_milli_seconds(translated_subs[index-1].end)\n",
    "\n",
    "        if subtitle_index ==1:\n",
    "            voice_muted_original_audio = original_audio[:current_start]+ (original_audio[current_start:current_end]-80)\n",
    "        else:\n",
    "            voice_muted_original_audio = voice_muted_original_audio + original_audio[previous_end:current_start]+\\\n",
    "                                        (original_audio[current_start:current_end]-80)\n",
    "\n",
    "    last_end = get_milli_seconds(translated_subs[-1].end)\n",
    "    voice_muted_original_audio = voice_muted_original_audio +original_audio[last_end:]\n",
    "    \n",
    "    return voice_muted_original_audio\n",
    "\n",
    "def save_final_audio(filename_translated,voice_muted_original_audio,final_audio_name):\n",
    "    counter = 0\n",
    "    translated_subs = pysrt.open(filename_translated,encoding='utf-8')\n",
    "    for index,each in enumerate(translated_subs):\n",
    "        subtitle_index = index+1\n",
    "        content = each.text\n",
    "        current_start = get_milli_seconds(each.start)\n",
    "        current_end = get_milli_seconds(each.end)\n",
    "        append_string = '__'+str(subtitle_index)+'.wav'\n",
    "        wavfilename = filename_translated.replace('.srt',append_string)\n",
    "        temp = AudioSegment.from_wav(wavfilename)\n",
    "        start_timecode = current_start - 100\n",
    "        start_timecode = max(start_timecode,0)\n",
    "        voice_muted_original_audio = voice_muted_original_audio.overlay(temp,position=start_timecode)\n",
    "        orig_duration = current_end-current_start\n",
    "        translated_duration = len(temp)\n",
    "        difference = abs(translated_duration-orig_duration)\n",
    "        if (difference > 300):\n",
    "            print (content)\n",
    "            counter = counter + 1\n",
    "        print (content)\n",
    "        print (\"original duration in millisecs: \",orig_duration, 'Translated duration: ',translated_duration,\"difference: \",difference, \"index \",subtitle_index)\n",
    "\n",
    "    voice_muted_original_audio.export(final_audio_name, format=\"wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62df2d12-5af2-470d-860f-95fe4eea9e7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "srt_file_name = job_name + '_translated.srt'\n",
    "output_file_path = '/tmp/'+srt_file_name\n",
    "print (\"Filename \",srt_file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15ac6d-d09e-49a8-9df8-c974849ebb50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bucket_name = \"sunil-video-translation-output-translated-srt\" \n",
    "s3.download_file(bucket_name,srt_file_name, output_file_path)\n",
    "\n",
    "base_filename_json = srt_file_name.rsplit('.',1)[0]\n",
    "language_string = base_filename_json.rsplit(\"__\",2)\n",
    "source_language_code = language_string[-2].split('-')[0].lower()\n",
    "target_language_code= language_string[-1].lower().split('_')[0]\n",
    "source_language_code\n",
    "target_language_code\n",
    "voice_id = voiceid_list[target_language_code]\n",
    "voice_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f5982-5131-4fac-9bc9-35b0cdb8ba64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "write_mp3_files(output_file_path,voice_id)\n",
    "print (\" Finished - write_mp3_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92067f86-b308-4536-b6e8-d9efbb6f6625",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.listdir('/tmp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6319d733-9240-4613-b854-0ac3b8b2e4ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "audio_output_path = './audio_files/' + job_name + '.wav'\n",
    "original_audio = AudioSegment.from_wav(audio_output_path)\n",
    "audio_length = original_audio.duration_seconds\n",
    "print(\"audio_length:\",audio_length)\n",
    "\n",
    "voice_muted_original_audio = save_voice_muted_audio_file(output_file_path,original_audio)\n",
    "print (\"Finished - save_voice_muted_audio_file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb40f1c-bd58-4dca-90c7-9c85be8538a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_audio_path =  audio_output_path.replace(\".wav\",\"_final.wav\")\n",
    "save_final_audio(output_file_path,voice_muted_original_audio,final_audio_path)\n",
    "print (\"Saved original audio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26efadf9-2c61-4577-b9bc-221d5b0c493e",
   "metadata": {},
   "source": [
    "### STEP-6 Attach Audio to Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272ac942",
   "metadata": {},
   "source": [
    "<img src=\"./images/Arch_Diagram_Step-6.jpg\" alt=\"drawing\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932a969b-710d-4f98-9c77-9ba25ff53643",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Attach translated speech to original file\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "\n",
    "videoclip = VideoFileClip(youtube_filename)\n",
    "translated_audio = AudioFileClip(final_audio_path)\n",
    "new_clip = videoclip.set_audio(translated_audio)\n",
    "\n",
    "print(\"Attaching translated_audio:\", translated_audio)\n",
    "print(\"Using Video file:\", youtube_filename)\n",
    "\n",
    "translated_video = youtube_filename.replace(\".mp4\",\"_translated.mp4\")\n",
    "new_clip.write_videofile(translated_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3132cb58-7728-4f5d-a325-318cad57e924",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
